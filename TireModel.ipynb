{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGxm60Ps/KXTOrt2mkSt2J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Formula-Electric-Berkeley/FEBSim/blob/main/TireModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tire Modeling and Analysis for Formula Electric at Berkeley\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Welcome to the Tire Modeling notebook for the Formula Electric Berkeley! This tool allows you to analyze TTC testing data for the current tire set used in Round 9 testing, represented by files with the prefix **B2356**.\n",
        "\n",
        "## Getting Started\n",
        "\n",
        "To begin, please upload a TTC `.dat` file with a name that starts with **B2356**. This file should contain data on tire forces, moments, and slip angles. A typical file name format is `B2356raw5.dat`, where:\n",
        "\n",
        "* **B2356** refers to Round 9 of TTC testing, the current tire data.\n",
        "* **raw5** (the number following \"raw\") represents a specific file in the series.\n",
        "\n",
        "## Modeling Different Tire Data\n",
        "\n",
        "To model other tires or datasets, modify the following variables in each cell:\n",
        "\n",
        "* **file_name**: Update the prefix to the appropriate tire dataset code if you want to use data other than B2356.\n",
        "* **file_numbers**: Add or adjust numbers in the `file_numbers` list to reflect the specific files you want to analyze. For instance, setting `file_numbers` to `[1, 2, 3, ..., 15]` will process files named from `B2356raw1.dat` to `B2356raw15.dat`.\n",
        "\n",
        "## Instructions\n",
        "\n",
        "1. Upload your `.dat` file(s) and adjust the `file_name` and `file_numbers` variables as needed.\n",
        "2. Execute whichever cell you need data from.\n",
        "\n",
        "Enjoy exploring your tire data!"
      ],
      "metadata": {
        "id": "q3YyD7Ms1VJt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Raw Plot of FY vs SA:</h2>\n"
      ],
      "metadata": {
        "id": "O3Xwlzpb1uTm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jp7MVmbddsjh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objs as go\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=pd.errors.DtypeWarning)\n",
        "\n",
        "# Define the column names\n",
        "column_names = ['ET', 'V', 'N', 'SA', 'IA', 'RL', 'RE', 'P', 'FX', 'FY', 'FZ', 'MX', 'MZ',\n",
        "                'NFX', 'NFY', 'RST', 'TSTI', 'TSTC', 'TSTO', 'AMBTMP', 'SR']\n",
        "\n",
        "def read_and_process_file(file_path):\n",
        "    # Load the data with flexible handling of bad lines and proper column names\n",
        "    data = pd.read_csv(file_path, delim_whitespace=True, names=column_names, on_bad_lines='skip')\n",
        "\n",
        "    # Drop the first two rows and reset the index\n",
        "    data = data.iloc[2:].reset_index(drop=True)\n",
        "\n",
        "    # Convert all columns to numeric types, coercing errors to NaN\n",
        "    data = data.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    # Drop any rows with NaN values in any column\n",
        "    data.dropna(inplace=True)\n",
        "\n",
        "    return data\n",
        "\n",
        "# List of file numbers to process\n",
        "file_numbers = [2, 4, 5, 6, 7, 8, 9]\n",
        "\n",
        "# Dictionary to hold DataFrames for each file\n",
        "dataframes = {}\n",
        "\n",
        "# Read and process each file\n",
        "for num in file_numbers:\n",
        "    file_name = f'B2356raw{num}.dat'\n",
        "    data_path = f'{file_name}'\n",
        "    df = read_and_process_file(data_path)\n",
        "    dataframes[num] = df\n",
        "\n",
        "# Create the Plotly figure\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add a trace for each dataset, initially set to not visible\n",
        "for num in file_numbers:\n",
        "    df = dataframes[num]\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=df['SA'], y=df['FY'],\n",
        "        mode='markers',\n",
        "        name=f'File {num}',\n",
        "        visible=False  # Set all traces to be invisible initially\n",
        "    ))\n",
        "\n",
        "# Set the first dataset to be visible by default\n",
        "fig.data[0].visible = True\n",
        "\n",
        "# Create buttons to toggle between datasets\n",
        "buttons = []\n",
        "for i, num in enumerate(file_numbers):\n",
        "    # Create a list of visibility settings for each trace\n",
        "    visible = [False] * len(file_numbers)\n",
        "    visible[i] = True  # Only the current dataset is visible\n",
        "\n",
        "    # Define a button that updates the figure\n",
        "    button = dict(\n",
        "        label=f'File {num}',\n",
        "        method='update',\n",
        "        args=[\n",
        "            {'visible': visible},  # Update the visibility list\n",
        "            {'title': f'FY vs SA for File {num}'}  # Update the title\n",
        "        ]\n",
        "    )\n",
        "    buttons.append(button)\n",
        "\n",
        "# Add the buttons to the layout\n",
        "fig.update_layout(\n",
        "    updatemenus=[\n",
        "        dict(\n",
        "            active=0,\n",
        "            buttons=buttons,\n",
        "            x=1.15,\n",
        "            xanchor='right',\n",
        "            y=1.15,\n",
        "            yanchor='top'\n",
        "        )\n",
        "    ],\n",
        "    title=f'FY vs SA for File {file_numbers[0]}',\n",
        "    xaxis_title='SA',\n",
        "    yaxis_title='FY'\n",
        ")\n",
        "\n",
        "# Save the figure to an HTML file\n",
        "fig.write_html('FY_vs_SA.html')\n",
        "\n",
        "print(\"Interactive plot saved as 'FY_vs_SA.html'. You can open this file in a web browser to view the plot.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Raw Plot of MZ vs SA</h2>"
      ],
      "metadata": {
        "id": "arcPclQq3eY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "# Define the column names\n",
        "column_names = ['ET', 'V', 'N', 'SA', 'IA', 'RL', 'RE', 'P', 'FX', 'FY', 'FZ', 'MX', 'MZ',\n",
        "                'NFX', 'NFY', 'RST', 'TSTI', 'TSTC', 'TSTO', 'AMBTMP', 'SR']\n",
        "\n",
        "def read_and_process_file(file_path):\n",
        "    # Load the data with flexible handling of bad lines and proper column names\n",
        "    data = pd.read_csv(file_path, delim_whitespace=True, names=column_names, on_bad_lines='skip')\n",
        "\n",
        "    # Drop the first two rows and reset the index\n",
        "    data = data.iloc[2:].reset_index(drop=True)\n",
        "\n",
        "    # Convert all columns to numeric types, coercing errors to NaN\n",
        "    data = data.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    # Drop any rows with NaN values in any column\n",
        "    data.dropna(inplace=True)\n",
        "\n",
        "    return data\n",
        "\n",
        "# List of file numbers to process\n",
        "file_numbers = [2, 4, 5, 6, 7, 8, 9]\n",
        "\n",
        "# Dictionary to hold DataFrames for each file\n",
        "dataframes = {}\n",
        "\n",
        "# Read and process each file\n",
        "for num in file_numbers:\n",
        "    file_name = f'B2356raw{num}.dat'\n",
        "    data_path = f'{file_name}'\n",
        "    df = read_and_process_file(data_path)\n",
        "    dataframes[num] = df\n",
        "\n",
        "# Create the Plotly figure\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add a trace for each dataset, initially set to not visible\n",
        "for num in file_numbers:\n",
        "    df = dataframes[num]\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=df['SA'], y=df['MZ'],\n",
        "        mode='markers',\n",
        "        name=f'File {num}',\n",
        "        visible=False  # Set all traces to be invisible initially\n",
        "    ))\n",
        "\n",
        "# Set the first dataset to be visible by default\n",
        "fig.data[0].visible = True\n",
        "\n",
        "# Create buttons to toggle between datasets\n",
        "buttons = []\n",
        "for i, num in enumerate(file_numbers):\n",
        "    # Create a list of visibility settings for each trace\n",
        "    visible = [False] * len(file_numbers)\n",
        "    visible[i] = True  # Only the current dataset is visible\n",
        "\n",
        "    # Define a button that updates the figure\n",
        "    button = dict(\n",
        "        label=f'File {num}',\n",
        "        method='update',\n",
        "        args=[\n",
        "            {'visible': visible},  # Update the visibility list\n",
        "            {'title': f'MZ vs SA for File {num}'}  # Update the title\n",
        "        ]\n",
        "    )\n",
        "    buttons.append(button)\n",
        "\n",
        "# Add the buttons to the layout\n",
        "fig.update_layout(\n",
        "    updatemenus=[\n",
        "        dict(\n",
        "            active=0,\n",
        "            buttons=buttons,\n",
        "            x=1.15,\n",
        "            xanchor='right',\n",
        "            y=1.15,\n",
        "            yanchor='top'\n",
        "        )\n",
        "    ],\n",
        "    title=f'MZ vs SA for File {file_numbers[0]}',\n",
        "    xaxis_title='SA',\n",
        "    yaxis_title='MZ'\n",
        ")\n",
        "\n",
        "# Save the figure to an HTML file\n",
        "fig.write_html('MZ_vs_SA.html')\n",
        "\n",
        "print(\"Interactive plot saved as 'MZ_vs_SA.html'. You can open this file in a web browser to view the plot.\")\n"
      ],
      "metadata": {
        "id": "qpVeRGcRgA15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.optimize import curve_fit\n",
        "\n",
        "# Define the correct column names\n",
        "column_names = ['ET', 'V', 'N', 'SA', 'IA', 'RL', 'RE', 'P', 'FX', 'FY', 'FZ', 'MX', 'MZ',\n",
        "                'NFX', 'NFY', 'RST', 'TSTI', 'TSTC', 'TSTO', 'AMBTMP', 'SR']\n",
        "\n",
        "# Function to load and prepare the data\n",
        "def load_and_prepare_dataframe(file_path):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, delim_whitespace=True, names=column_names, on_bad_lines='skip')\n",
        "        print(f\"Successfully loaded {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load {file_path}. Error: {e}\")\n",
        "        return None\n",
        "\n",
        "    df = df.iloc[2:].reset_index(drop=True)\n",
        "\n",
        "    # Drop empty or zero-length dataframes\n",
        "    if len(df) > 0:\n",
        "        return df\n",
        "    else:\n",
        "        print(f\"File {file_path} has zero length after preprocessing.\")\n",
        "        return None\n",
        "\n",
        "# Function to clean data\n",
        "def clean_data(df):\n",
        "    df['FY'] = pd.to_numeric(df['FY'], errors='coerce')  # Lateral force\n",
        "    df['SA'] = pd.to_numeric(df['SA'], errors='coerce')  # Slip angle\n",
        "    df['FZ'] = pd.to_numeric(df['FZ'], errors='coerce')  # Vertical load\n",
        "    df['IA'] = pd.to_numeric(df['IA'], errors='coerce')  # Camber angle\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df.dropna(subset=['FY', 'SA', 'FZ', 'IA'], inplace=True)\n",
        "    df['FZ'] = np.abs(df['FZ'])  # Ensure FZ is positive\n",
        "    return df\n",
        "\n",
        "# Extended Pacejka '94 Magic Formula for lateral force with FZ dependency\n",
        "def pacejka_lateral_combined(SA, FZ, p):\n",
        "    \"\"\"\n",
        "    Pacejka lateral force model with vertical load dependency.\n",
        "    SA: Slip angle in radians\n",
        "    FZ: Vertical load in N (positive)\n",
        "    p: Parameters array [B0, B1, C0, D0, D1, E0, E1]\n",
        "    \"\"\"\n",
        "    B0, B1, C0, D0, D1, E0, E1 = p\n",
        "    D = (D0 + D1 * FZ) * FZ\n",
        "    B = B0 + B1 * FZ\n",
        "    C = C0\n",
        "    E = E0 + E1 * FZ\n",
        "    return D * np.sin(C * np.arctan(B * SA - E * (B * SA - np.arctan(B * SA))))\n",
        "\n",
        "# Function to fit the combined Pacejka model to the tire data\n",
        "def fit_pacejka_combined(df):\n",
        "    SA = np.radians(df['SA'].values)  # Convert slip angle to radians\n",
        "    FZ = df['FZ'].values\n",
        "    FY = df['FY'].values\n",
        "\n",
        "    # Initial guess for parameters\n",
        "    initial_guess = [0.01, 0.0001, 1.4, 1.0, 0.0001, 0.97, 0.0001]\n",
        "\n",
        "    # Fit the model\n",
        "    try:\n",
        "        params, _ = curve_fit(\n",
        "            lambda xdata, *p: pacejka_lateral_combined(xdata[0], xdata[1], p),\n",
        "            (SA, FZ), FY, p0=initial_guess, maxfev=100000\n",
        "        )\n",
        "        return params\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Curve fitting failed: {e}\")\n",
        "        return None\n",
        "\n",
        "# Main script\n",
        "if __name__ == \"__main__\":\n",
        "    # Load data and fit Pacejka model\n",
        "    file_path = '0DegConcatTireData_shifted_scaled_1000.dat'  # Replace with your data file path\n",
        "    df = load_and_prepare_dataframe(file_path)\n",
        "    if df is not None:\n",
        "        df = clean_data(df)\n",
        "        pacejka_params = fit_pacejka_combined(df)\n",
        "\n",
        "        if pacejka_params is None:\n",
        "            print(\"Failed to fit the Pacejka model.\")\n",
        "        else:\n",
        "            # Vehicle parameters\n",
        "            mass = 310  # Total mass of the car in kg\n",
        "            mass_per_axle = mass / 2  # Mass per axle\n",
        "            g = 9.81  # Acceleration due to gravity\n",
        "            static_axle_weight = mass_per_axle * g  # Static weight per axle in N\n",
        "\n",
        "            # Fixed camber angles\n",
        "            camber_outside = 0  # degrees\n",
        "            camber_inside = -1  # degrees\n",
        "\n",
        "            # Vehicle geometry\n",
        "            h_cg = 0.25  # Center of gravity height in meters\n",
        "            track_width = 1.05  # Track width in meters\n",
        "\n",
        "            # Aerodynamic parameters\n",
        "            downforce_values = np.arange(200, 2000, 50)  # More granular range from 400 to 2000 in increments of 50\n",
        "            aero_balance = 0.5  # Fraction of downforce on the front axle\n",
        "\n",
        "            results_list = []\n",
        "\n",
        "            for downforce in downforce_values:\n",
        "                # Distribute downforce to the axle\n",
        "                axle_downforce = downforce * aero_balance  # Adjust for front or rear axle as needed\n",
        "\n",
        "                # Total axle weight including downforce\n",
        "                axle_weight = static_axle_weight + axle_downforce  # Total vertical force on axle (N)\n",
        "\n",
        "                # Lateral acceleration range to evaluate\n",
        "                lateral_acc_values = np.linspace(0.1, 2.0, 50) * g  # From 0.1g to 2.0g\n",
        "\n",
        "                for lateral_acc in lateral_acc_values:\n",
        "                    # Calculate load transfer using vehicle mass (not axle weight)\n",
        "                    load_transfer = (mass_per_axle * lateral_acc * h_cg) / track_width  # Load transfer in N\n",
        "\n",
        "                    # Vertical loads on outside and inside tires\n",
        "                    FZ_outside = (axle_weight / 2) + load_transfer\n",
        "                    FZ_inside = (axle_weight / 2) - load_transfer\n",
        "\n",
        "                    # Ensure vertical loads are positive\n",
        "                    if FZ_inside <= 0:\n",
        "                        break  # Inside tire has lifted off\n",
        "\n",
        "                    # Compute maximum lateral force for each tire\n",
        "                    SA_values = np.radians(np.linspace(-15, 15, 100))  # Slip angle range in radians\n",
        "\n",
        "                    # Outside tire\n",
        "                    FY_o_values = pacejka_lateral_combined(SA_values, FZ_outside, pacejka_params)\n",
        "                    max_index_o = np.argmax(FY_o_values)\n",
        "                    SA_o_opt = SA_values[max_index_o]\n",
        "                    FY_o_max = FY_o_values[max_index_o]\n",
        "\n",
        "                    # Inside tire\n",
        "                    FY_i_values = pacejka_lateral_combined(SA_values, FZ_inside, pacejka_params)\n",
        "                    max_index_i = np.argmax(FY_i_values)\n",
        "                    SA_i_opt = SA_values[max_index_i]\n",
        "                    FY_i_max = FY_i_values[max_index_i]\n",
        "\n",
        "                    # Apply camber effect (simplified linear model)\n",
        "                    camber_coefficient = 0.01  # Adjust as needed\n",
        "                    camber_effect_outside = 1 + camber_coefficient * camber_outside\n",
        "                    camber_effect_inside = 1 + camber_coefficient * camber_inside\n",
        "\n",
        "                    FY_o_max *= camber_effect_outside\n",
        "                    FY_i_max *= camber_effect_inside\n",
        "\n",
        "                    # Total lateral force for the axle\n",
        "                    total_FY = FY_o_max + FY_i_max\n",
        "\n",
        "                    # Calculated lateral acceleration based on total lateral force\n",
        "                    lateral_acc_calc = total_FY / (mass_per_axle * g)  # Divide by weight per axle\n",
        "\n",
        "                    results_list.append({\n",
        "                        'Downforce (N)': downforce,\n",
        "                        'Lateral Acceleration (g)': lateral_acc / g,\n",
        "                        'FZ Outside (N)': FZ_outside,\n",
        "                        'FZ Inside (N)': FZ_inside,\n",
        "                        'FY Outside (N)': FY_o_max,\n",
        "                        'FY Inside (N)': FY_i_max,\n",
        "                        'Total FY (N)': total_FY,\n",
        "                        'Calculated Lateral Acc (g)': lateral_acc_calc,\n",
        "                        'Optimal SA Outside (deg)': np.degrees(SA_o_opt),\n",
        "                        'Optimal SA Inside (deg)': np.degrees(SA_i_opt)\n",
        "                    })\n",
        "\n",
        "            # Create dataframe\n",
        "            results_df = pd.DataFrame(results_list)\n",
        "\n",
        "            # Output the dataframe\n",
        "            print(results_df)\n",
        "\n",
        "            # Save the results to an Excel file\n",
        "            results_df.to_excel('tire_results_fixed_camber_with_downforce.xlsx', index=False)\n",
        "            print(\"Results have been saved to 'tire_results_fixed_camber_with_downforce.xlsx'.\")\n",
        "    else:\n",
        "        print(\"Dataframe could not be loaded and processed.\")\n"
      ],
      "metadata": {
        "id": "IT2mn-871D5R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}